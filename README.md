<div align="center">

# ğŸ¬ VoxDub - AI Video Dubbing System

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104.1-009688.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18.2.0-61DAFB.svg)](https://reactjs.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**Professional AI-powered video dubbing with automatic translation and lip synchronization**

Transform videos into any language with natural voice synthesis and perfect lip-sync using state-of-the-art AI models.

[Features](#-features) â€¢ [Demo](#-demo) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Architecture](#-architecture)

</div>

---

## âœ¨ Features

- ğŸ™ï¸ **Automatic Speech Recognition** - Powered by OpenAI Whisper (99 languages)
- ğŸŒ **Neural Machine Translation** - Meta NLLB-200 (200+ languages)
- ğŸ—£ï¸ **Natural Voice Synthesis** - High-quality Coqui TTS
- ğŸ’‹ **Lip Synchronization** - Realistic Wav2Lip GAN
- ğŸ“Š **Real-time Progress Tracking** - Live processing status updates
- ğŸ¨ **Professional UI/UX** - Clean, modern, responsive interface
- âš¡ **Async Processing** - Fast, non-blocking architecture
- ğŸ”’ **Secure** - Files automatically deleted after 24 hours

---

## ğŸ¯ Demo

### How It Works

Input Video (English) â†’ VoxDub AI Pipeline â†’ Output Video (Spanish + Lip Sync)

1. **Upload** a video in any language
2. **Select** target language from 200+ options
3. **Process** with AI (3-5 minutes)
4. **Download** professionally dubbed video

**Supported Formats:** MP4, AVI, MOV, MKV  
**Max File Size:** 500 MB  
**Processing Time:** 2-5 minutes (depending on video length)

---

## ğŸ—ï¸ Architecture

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ React Frontend (Vite) â”‚
â”‚ Modern UI with Real-time Progress Tracking â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ REST API (HTTP/JSON)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FastAPI Backend (Python) â”‚
â”‚ Asynchronous AI Processing Pipeline â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â–¼ â–¼ â–¼ â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Whisper â”‚ â”‚ NLLB â”‚ â”‚Coqui TTS â”‚ â”‚ Wav2Lip â”‚
â”‚ AI â”‚ â”‚Translationâ”‚ â”‚ Voices â”‚ â”‚ Lip-Sync â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜



### Processing Pipeline

Audio Extraction (FFmpeg)
â†“

Speech Recognition (Whisper) â†’ Text + Language
â†“

Translation (NLLB) â†’ Translated Text
â†“

Voice Synthesis (TTS) â†’ New Audio
â†“

Lip Synchronization (Wav2Lip) â†’ Final Video
â†“

Output Encoding (FFmpeg) â†’ Download Ready


---

## ğŸš€ Installation

### Prerequisites

Before you begin, ensure you have:

- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **Node.js 18+** ([Download](https://nodejs.org/))
- **FFmpeg** ([Download](https://ffmpeg.org/download.html))
- **8GB RAM** minimum (16GB recommended)
- **10GB disk space** (for AI models)

### Step 1: Clone Repository

git clone https://github.com/pranavpanchal1326/voxdub.git
cd voxdub


### Step 2: Backend Setup

cd backend

Create virtual environment
python -m venv venv

Activate virtual environment
Windows:
venv\Scripts\activate

Linux/Mac:
source venv/bin/activate

Upgrade pip
python -m pip install --upgrade pip

Install dependencies (this takes 10-15 minutes)
pip install -r requirements.txt


### Step 3: Download AI Models

**Wav2Lip Model (Required):**

Download from official repository
https://github.com/Rudrabha/Wav2Lip
Place checkpoint in:
backend/Wav2Lip/checkpoints/wav2lip_gan.pth
text

**Other models auto-download on first run:**
- Whisper (~140MB)
- NLLB (~2.5GB)
- Coqui TTS (~200MB)

**First run takes 5-10 minutes to load models.**

### Step 4: Frontend Setup

cd ../frontend

Install dependencies
npm install

Build for production (optional)
npm run build

text

### Step 5: Configure FFmpeg

**Windows:**
Download FFmpeg from: https://ffmpeg.org/download.html
Add to PATH or place in project folder
text

**Linux:**
sudo apt update
sudo apt install ffmpeg

text

**Mac:**
brew install ffmpeg

text

**Verify installation:**
ffmpeg -version

text

---

## ğŸ® Usage

### Running the Application

Open **two terminals**:

**Terminal 1 - Backend:**
cd backend
venv\Scripts\activate # Windows

source venv/bin/activate # Linux/Mac
python app.py

text

**Terminal 2 - Frontend:**
cd frontend
npm run dev

text

**Open in browser:** http://localhost:5173

### Using the Application

1. **Upload Video**
   - Click upload area or drag & drop
   - Supported: MP4, AVI, MOV, MKV
   - Max size: 500MB

2. **Select Target Language**
   - Choose from 200+ languages
   - Auto-detects source language

3. **Start Processing**
   - Watch real-time progress
   - 5 processing stages displayed

4. **Download Result**
   - Video with dubbed audio
   - Lip movements synchronized
   - Same quality as original

---

## ğŸ§  AI Models

| Model | Purpose | Size | Provider | Accuracy |
|-------|---------|------|----------|----------|
| **Whisper Base** | Speechâ†’Text | 140MB | OpenAI | 95%+ |
| **NLLB-200** | Translation | 2.5GB | Meta AI | 90%+ |
| **Coqui TTS** | Textâ†’Speech | 200MB | Coqui | 90%+ |
| **Wav2Lip GAN** | Lip Sync | 350MB | IISc | 95%+ |

**Total Model Size:** ~3.2GB  
**Supported Languages:** 200+  
**Processing Speed:** 2-5 minutes per video

---

## ğŸ“‚ Project Structure

voxdub/
â”œâ”€â”€ backend/ # Python FastAPI backend
â”‚ â”œâ”€â”€ app.py # Main FastAPI application
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â”‚
â”‚ â”œâ”€â”€ models/ # AI model integrations
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ transcription.py # Whisper wrapper
â”‚ â”‚ â”œâ”€â”€ translation.py # NLLB wrapper
â”‚ â”‚ â”œâ”€â”€ voice_synthesis.py # TTS wrapper
â”‚ â”‚ â””â”€â”€ lipsync.py # Wav2Lip wrapper
â”‚ â”‚
â”‚ â”œâ”€â”€ utils/ # Utility modules
â”‚ â”‚ â”œâ”€â”€ init.py
â”‚ â”‚ â”œâ”€â”€ video_processor.py # FFmpeg operations
â”‚ â”‚ â””â”€â”€ file_handler.py # File management
â”‚ â”‚
â”‚ â”œâ”€â”€ Wav2Lip/ # Wav2Lip repository
â”‚ â”‚ â”œâ”€â”€ models/
â”‚ â”‚ â”œâ”€â”€ checkpoints/ # Model weights (download)
â”‚ â”‚ â””â”€â”€ inference.py
â”‚ â”‚
â”‚ â””â”€â”€ venv/ # Virtual environment
â”‚
â”œâ”€â”€ frontend/ # React frontend
â”‚ â”œâ”€â”€ src/
â”‚ â”‚ â”œâ”€â”€ main.jsx # React entry
â”‚ â”‚ â”œâ”€â”€ App.jsx # Main component
â”‚ â”‚ â”œâ”€â”€ App.css # App styles
â”‚ â”‚ â”œâ”€â”€ index.css # Global styles
â”‚ â”‚ â”‚
â”‚ â”‚ â””â”€â”€ components/ # React components
â”‚ â”‚ â”œâ”€â”€ VideoUpload.jsx
â”‚ â”‚ â”œâ”€â”€ VideoUpload.css
â”‚ â”‚ â”œâ”€â”€ LanguageSelector.jsx
â”‚ â”‚ â”œâ”€â”€ LanguageSelector.css
â”‚ â”‚ â”œâ”€â”€ ProcessingStatus.jsx
â”‚ â”‚ â”œâ”€â”€ ProcessingStatus.css
â”‚ â”‚ â”œâ”€â”€ ResultPreview.jsx
â”‚ â”‚ â””â”€â”€ ResultPreview.css
â”‚ â”‚
â”‚ â”œâ”€â”€ public/ # Static assets
â”‚ â”œâ”€â”€ index.html # HTML template
â”‚ â”œâ”€â”€ package.json # npm dependencies
â”‚ â””â”€â”€ vite.config.js # Vite config
â”‚
â”œâ”€â”€ uploads/ # User uploaded videos (auto-created)
â”œâ”€â”€ outputs/ # Processed videos (auto-created)
â”œâ”€â”€ temp/ # Temporary files (auto-created)
â”‚
â”œâ”€â”€ .gitignore # Git ignore rules
â”œâ”€â”€ README.md # This file
â””â”€â”€ LICENSE # MIT License

text

---

## ğŸ› ï¸ Technology Stack

### Backend
- **FastAPI** - Modern async Python web framework
- **Uvicorn** - ASGI server
- **PyTorch** - Deep learning framework
- **Transformers** - Hugging Face model hub
- **OpenCV** - Computer vision library
- **Librosa** - Audio processing
- **FFmpeg** - Video/audio manipulation

### Frontend
- **React 18** - UI library
- **Vite** - Next-generation build tool
- **Axios** - HTTP client
- **Modern CSS** - Professional styling

### AI/ML
- **OpenAI Whisper** - Speech recognition
- **Meta NLLB** - Neural translation
- **Coqui TTS** - Text-to-speech
- **Wav2Lip** - Lip synchronization

---

## âš™ï¸ Configuration

### Environment Variables (Optional)

Create `.env` in `backend/` folder:

Server Configuration
HOST=0.0.0.0
PORT=8000
DEBUG=False

Model Configuration
WHISPER_MODEL=base
NLLB_MODEL=facebook/nllb-200-distilled-600M
TTS_MODEL=tts_models/multilingual/multi-dataset/your_tts

File Limits
MAX_FILE_SIZE_MB=500
ALLOWED_FORMATS=mp4,avi,mov,mkv
AUTO_DELETE_HOURS=24

Processing
USE_GPU=True
MAX_WORKERS=2

text

---

## ğŸ“Š API Documentation

Once backend is running, visit:

- **Swagger UI:** http://localhost:8000/docs
- **ReDoc:** http://localhost:8000/redoc

### Key Endpoints

POST /api/dub - Upload video and start dubbing
GET /api/status/{job_id} - Check processing status
GET /api/download/{job_id} - Download processed video
GET /api/languages - Get supported languages
GET /api/health - Health check

text

---

## ğŸ¬ Example Use Cases

- **Content Localization** - YouTubers dubbing videos for global audience
- **E-Learning** - Educational content translation
- **Marketing** - Multilingual advertising campaigns
- **Entertainment** - Indie film dubbing
- **Accessibility** - Making content accessible worldwide
- **Business** - International training videos

---

## ğŸš§ Troubleshooting

### Common Issues

**1. "FFmpeg not found"**
Verify FFmpeg is in PATH
ffmpeg -version

If not, add to PATH or install
text

**2. "Module not found" errors**
Reinstall dependencies
pip install -r requirements.txt



**3. "Out of memory" during processing**
Use smaller Whisper model in config
WHISPER_MODEL=tiny # Instead of 'base'

Or process shorter videos


**4. "Port 8000 already in use"**
Kill process using port
Windows:
netstat -ano | findstr :8000
taskkill /PID <PID> /F

Linux/Mac:
lsof -ti:8000 | xargs kill -9



**5. Slow processing**
- First run downloads models (10 mins)
- Subsequent runs are faster (2-5 mins)
- GPU significantly speeds up processing

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **OpenAI** - Whisper speech recognition model
- **Meta AI** - NLLB translation model
- **Coqui AI** - Text-to-speech system
- **IISc Bangalore** - Wav2Lip lip synchronization
- **FFmpeg** - Video/audio processing
- **Hugging Face** - Model hosting and transformers library

---

## ğŸ“§ Contact

**Pranav Panchal** - [GitHub](https://github.com/YOUR_USERNAME)

Project Link: [https://github.com/YOUR_USERNAME/voxdub](https://github.com/YOUR_USERNAME/voxdub)

---

## â­ Show Your Support

If you find this project helpful, please give it a â­ on GitHub!

---

<div align="center">

**Built with â¤ï¸ using AI and modern web technologies**

</div>